import streamlit as st
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# ==========================================
# 0. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(
    page_title="ê³¼ëª©ì¶”ì²œ AI",
    page_icon="ğŸ“",
    layout="centered"
)

st.title("ğŸ“ ìš°ë¦¬ í•™êµ ê³¼ëª©ì¶”ì²œ AI")
st.markdown("### ì§„ë¡œì— ë”± ë§ëŠ” ì„ íƒ ê³¼ëª©ì„ ì°¾ì•„ë³´ì„¸ìš”!")
st.divider()

# ==========================================
# 1. ë°ì´í„° ë¡œë“œ (ìºì‹± ì ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ)
# ==========================================
@st.cache_data
def load_data():
    try:
        # íŒŒì¼ëª…ì€ ì‹¤ì œ ì—…ë¡œë“œí•  íŒŒì¼ëª…ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
        school_df = pd.read_excel('school_subjects.xlsx')
        univ_df = pd.read_excel('univ_req1.xlsx')
        
        # ì „ì²˜ë¦¬
        if 'ê´€ë ¨í‚¤ì›Œë“œ' not in univ_df.columns: 
            univ_df['ê´€ë ¨í‚¤ì›Œë“œ'] = ''
        univ_df['ê´€ë ¨í‚¤ì›Œë“œ'] = univ_df['ê´€ë ¨í‚¤ì›Œë“œ'].fillna('')
        univ_df['í•™ê³¼ëª…'] = univ_df['í•™ê³¼ëª…'].fillna('')
        univ_df['search_text'] = univ_df['í•™ê³¼ëª…'] + " " + univ_df['ê´€ë ¨í‚¤ì›Œë“œ'].astype(str)
        
        return school_df, univ_df
    except Exception as e:
        return None, None

school_df, univ_df = load_data()

if school_df is None:
    st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (school_subjects.xlsx, univ_req1.xlsx)")
    st.stop()

# ==========================================
# 2. ë¡œì§ í•¨ìˆ˜ë“¤ (ìœ ì‚¬ë„ ë¶„ì„ & ì •ê·œí™”)
# ==========================================
def normalize(text):
    if pd.isna(text): return ""
    return str(text).replace(" ", "").lower().strip()

def find_best_major_smart(user_input, univ_df):
    # 1. í¬í•¨ ì—¬ë¶€ í™•ì¸
    mask = univ_df['search_text'].str.contains(user_input, case=False, na=False)
    matched_df = univ_df[mask]
    if not matched_df.empty:
        return matched_df.iloc[0], "match"

    # 2. ìœ ì‚¬ë„ ë¶„ì„
    try:
        tfidf = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3))
        documents = univ_df['search_text'].tolist()
        documents.append(user_input)
        
        tfidf_matrix = tfidf.fit_transform(documents)
        similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])
        best_match_idx = similarities.argsort()[0][-1]
        best_score = similarities[0][best_match_idx]
        
        if best_score > 0.05:
             return univ_df.iloc[best_match_idx], "sim"
    except:
        pass
    return None, None

# ==========================================
# 3. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° (UI)
# ==========================================
col1, col2 = st.columns(2)

with col1:
    grade_input = st.selectbox("ì§„ê¸‰í•  í•™ë…„ì„ ì„ íƒí•˜ì„¸ìš”", [2, 3])

with col2:
    user_interest = st.text_input("ê´€ì‹¬ ê³„ì—´/í•™ê³¼/í‚¤ì›Œë“œ ì…ë ¥", placeholder="ì˜ˆ: ê¸°ê³„, ì˜ì˜ˆ, ì»´ê³µ, ë¡œë´‡")

search_btn = st.button("ğŸ” ê³¼ëª© ì¶”ì²œë°›ê¸°", type="primary")

# ==========================================
# 4. ê²°ê³¼ ì¶œë ¥ í™”ë©´
# ==========================================
if search_btn and user_interest:
    best_major, match_type = find_best_major_smart(user_interest, univ_df)
    
    if best_major is None:
        st.error(f"ğŸ˜¥ '{user_interest}'ì™€ ê´€ë ¨ëœ í•™ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.info("ì¡°ê¸ˆ ë” ì¼ë°˜ì ì¸ ë‹¨ì–´ë‚˜ ì •í™•í•œ í•™ê³¼ëª…ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.")
    else:
        # í•™ê³¼ ì°¾ìŒ ì„±ê³µ ë©”ì‹œì§€
        st.success(f"ğŸ‰ **[{best_major['í•™ê³¼ëª…']}]** ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        
        # ëŒ€í•™ ìš”êµ¬ì‚¬í•­ íŒŒì‹±
        req_subjects = [x.strip() for x in str(best_major.get('í•„ìˆ˜ì´ìˆ˜ê³¼ëª©(ìˆ˜í•™)','')).split(',') if x.strip() not in ['-', 'nan', '']] + \
                       [x.strip() for x in str(best_major.get('í•„ìˆ˜ì´ìˆ˜ê³¼ëª©(ê³¼í•™)','')).split(',') if x.strip() not in ['-', 'nan', '']]
        
        rec_subjects = [x.strip() for x in str(best_major.get('ê¶Œì¥ì´ìˆ˜ê³¼ëª©(ìˆ˜í•™)','')).split(',') if x.strip() not in ['-', 'nan', '']] + \
                       [x.strip() for x in str(best_major.get('ê¶Œì¥ì´ìˆ˜ê³¼ëª©(ê³¼í•™/ì •ë³´)','')).split(',') if x.strip() not in ['-', 'nan', '']]
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = [x.strip() for x in str(best_major.get('ê´€ë ¨í‚¤ì›Œë“œ','')).split(',') if x.strip()]
        keywords.append(best_major['í•™ê³¼ëª…'].replace("í•™ê³¼", "").replace("ê³µí•™", "").replace("ë¶€", ""))

        # ëŒ€í•™ ìš”êµ¬ ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ“Œ ëŒ€í•™ì—ì„œ ìš”êµ¬í•˜ëŠ” ê³¼ëª© ë³´ê¸° (í´ë¦­)", expanded=True):
            st.markdown(f"**í•„ìˆ˜(â­â­â­):** {', '.join(req_subjects) if req_subjects else 'ì—†ìŒ'}")
            st.markdown(f"**ê¶Œì¥(â­â­):** {', '.join(rec_subjects) if rec_subjects else 'ì—†ìŒ'}")

        st.divider()
        st.subheader(f"ğŸ« {grade_input}í•™ë…„ ì¶”ì²œ ê³¼ëª© ë¦¬ìŠ¤íŠ¸")

        # í•™êµ ë°ì´í„° í•„í„°ë§
        my_grade_subjects = school_df[school_df['í•™ë…„'] == grade_input].copy()
        
        if my_grade_subjects.empty:
            st.warning("í•´ë‹¹ í•™ë…„ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            grouped = my_grade_subjects.groupby('ì„ íƒêµ°ID')
            
            for group_id, group_df in grouped:
                group_info = group_df.iloc[0]
                category = group_info['êµê³¼êµ°']
                semester = group_info['í•™ê¸°']
                select_rule = group_info['ë¹„ê³ (ì„ íƒìˆ˜)']
                
                # ì¹´ë“œ í˜•íƒœë¡œ ë³´ì—¬ì£¼ê¸°
                with st.container():
                    st.markdown(f"#### ğŸ“… {semester}í•™ê¸° | {category} ({select_rule})")
                    
                    result_rows = []
                    for _, subject in group_df.iterrows():
                        sub_name = subject['ê³¼ëª©ëª…']
                        sub_norm = normalize(sub_name)
                        
                        icon = ""
                        note = ""
                        highlight = False
                        
                        # ë§¤ì¹­ ë¡œì§
                        is_match = False
                        
                        # 1. í•„ìˆ˜
                        for req in req_subjects:
                            if normalize(req) in sub_norm:
                                icon = "â­â­â­"
                                note = "í•„ìˆ˜ ì¶”ì²œ"
                                highlight = True
                                is_match = True
                                break
                        
                        # 2. ê¶Œì¥
                        if not is_match:
                            for rec in rec_subjects:
                                if normalize(rec) in sub_norm:
                                    icon = "â­â­"
                                    note = "ê¶Œì¥ ì¶”ì²œ"
                                    highlight = True
                                    is_match = True
                                    break
                        
                        # 3. í‚¤ì›Œë“œ AI ì¶”ì²œ
                        if not is_match:
                            for key in keywords:
                                if len(key) >= 2 and key in sub_name:
                                    icon = "â­"
                                    note = "AI ì¶”ì²œ (ê´€ë ¨ë„ ë†’ìŒ)"
                                    highlight = True
                                    is_match = True
                                    break
                        
                        if highlight:
                            result_rows.append(f"**{icon} {sub_name} ({note})**")
                        else:
                            result_rows.append(f"<span style='color:gray'>{sub_name}</span>")
                    
                    # ê²°ê³¼ ì¶œë ¥ (HTML íƒœê·¸ í—ˆìš©)
                    for row in result_rows:
                        st.markdown(f"- {row}", unsafe_allow_html=True)
                    
                    st.markdown("---")
